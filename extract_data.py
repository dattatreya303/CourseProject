# -*- coding: utf-8 -*-
"""extract-data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jNKfYr5R1HseOOiE6bBIXgbCpuIDAq_G
"""

import pandas as pd
import json
from os import listdir
from os.path import isdir, isfile

meta_df = pd.read_csv(filepath_or_buffer='../data/metadata.tar.gz', sep='\t', header=0, encoding='utf-8')
meta_df

# {show_filename_prefix : show_description}
show_description_dict = pd.Series(meta_df.show_description.values,index=meta_df.show_filename_prefix).to_dict()
# print(list(show_description_dict.items())[:10])

with open('../preprocessed_data/show_descriptions.json', 'w') as fp:
    json.dump(show_description_dict, fp)

episode_description_dict = pd.Series(meta_df.episode_description.values,index=meta_df.episode_filename_prefix).to_dict()
# print(list(episode_description_dict.items())[:10])

with open('../preprocessed_data/episode_descriptions.json', 'w') as fp:
    json.dump(episode_description_dict, fp)

valid_segment_access = lambda seg: 'alternatives' in seg and len(seg['alternatives']) > 0 and 'transcript' in seg['alternatives'][0]
def construct_transcript_string(transcript_dict):
    segments = transcript_dict['results']
    return ' '.join([segment['alternatives'][0]['transcript'] for segment in segments if valid_segment_access(segment)])

def extract_episode_lists_and_transcripts(data_id):
    transcript_dir = '../data/spotify-podcasts-2020/podcasts-transcripts/' + str(data_id)
    subdir_names = [dir_name for dir_name in listdir(transcript_dir) if isdir(transcript_dir + '/' + dir_name)]
    show_episodes_dict = {} # {show_dir_name : episode_json_name}
    episode_transcript_dict = {} # {episode_prefix: transcript_text}
    for subdir_name in subdir_names:
        subdir_path = transcript_dir + '/' + subdir_name
        show_dir_names = [dir_name for dir_name in listdir(subdir_path) if isdir(subdir_path + '/' + dir_name) and dir_name not in show_episodes_dict]
        for show_dir_name in show_dir_names:
            show_dir_path = subdir_path + '/' + show_dir_name
            show_episodes_dict[show_dir_name] = []
            episode_file_names = [file_name for file_name in listdir(show_dir_path) if isfile(show_dir_path + '/' + file_name)]
            for episode_file_name in episode_file_names:
                episode_prefix = episode_file_name.split('.')[0]
                if episode_prefix in episode_transcript_dict:
                    continue
                show_episodes_dict[show_dir_name].append(episode_prefix)
                episode_file_path = show_dir_path + '/' + episode_file_name
                transcript_dict = {}
                with open(episode_file_path, 'r') as f:
                    transcript_dict = json.load(f)
                transcript_string = construct_transcript_string(transcript_dict)
                episode_transcript_dict[episode_prefix] = transcript_string
    return show_episodes_dict, episode_transcript_dict
# ep_list_dict, ep_transcript_dict = extract_episode_lists_and_transcripts(7)

with open('../preprocessed_data/show_episode_list_7.json', 'w') as fp:
    json.dump(ep_list_dict, fp)
with open('../preprocessed_data/episode_transcripts_7.json', 'w') as fp:
    json.dump(ep_transcript_dict, fp)

def generate_summ_dataset():
    column_names = ['episode_prefix', 'episode_transcript', 'episode_description']
    merged_transcript_df = pd.DataFrame([], columns=column_names)
    for i in range(8):
        ep_transcript_dict = {}
        with open('../preprocessed_data/episode_transcripts_' + str(i) + '.json') as fp:
            ep_transcript_dict = json.load(fp)
        data = [[ep_prefix, transcript, episode_description_dict[ep_prefix]] for ep_prefix, transcript in ep_transcript_dict.items() if ep_prefix in episode_description_dict]
        df = pd.DataFrame(data, columns=column_names)
        merged_transcript_df = merged_transcript_df.append(df)
        print(str(i) + ' done')
    merged_transcript_df.to_csv('../preprocessed_data/merged_prefix_transcript_description_summ.tsv', sep='\t')
generate_summ_dataset()

pd.read_csv('../preprocessed_data/merged_prefix_transcript_description_summ.tsv', sep='\t', header=0, encoding='utf-8')

t_df = pd.read_csv('/content/merged_prefix_transcriptTextRanked_description_summ_10k.tsv.zip', sep='\t', header=0, encoding='utf-8')
t_df[t_df['episode_transcript_textranked'] == t_df['episode_transcript_textranked']]

